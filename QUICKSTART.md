# Quick Start Guide - After Cloning from GitHub

Welcome! You've just cloned the **QSAR Validation Framework v4.1.0**. Here's how to get started in 5 minutes.

---

## âœ… Step 1: Verify You Have Everything

After cloning, your directory structure should look like this:

```
Roy-QSAR-Generative-dev/
â”œâ”€â”€ README.md                   # Main documentation
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ setup.py                    # Package installer
â”œâ”€â”€ src/                        # Framework source code
â”‚   â”œâ”€â”€ utils/                  # Core utilities
â”‚   â””â”€â”€ qsar_validation/        # Validation modules
â”œâ”€â”€ notebooks/                  # Example notebooks â­
â”‚   â”œâ”€â”€ README.md              # Notebook documentation
â”‚   â”œâ”€â”€ DATA_LEAKAGE_FIX_EXAMPLE.ipynb
â”‚   â”œâ”€â”€ Model_1_...ipynb
â”‚   â”œâ”€â”€ Model_2_...ipynb
â”‚   â”œâ”€â”€ Model_3_...ipynb
â”‚   â””â”€â”€ Model_4_...ipynb
â”œâ”€â”€ comprehensive_test/         # Test suite
â””â”€â”€ examples/                   # Example scripts
```

---

## ğŸš€ Step 2: Install Dependencies

```bash
# Make sure you're in the repository root
cd Roy-QSAR-Generative-dev

# Install all dependencies
pip install -r requirements.txt
```

**What gets installed:**
- Core: pandas, numpy, rdkit, scipy, matplotlib, seaborn
- ML: scikit-learn, xgboost (lightgbm is optional)
- Notebooks: jupyter

---

## ğŸ¯ Step 3: Choose Your Path

### Path A: I Want to Run the Example Notebooks ğŸ““

```bash
cd notebooks
jupyter notebook
```

1. Open `DATA_LEAKAGE_FIX_EXAMPLE.ipynb` first
2. Run all cells - it will work out of the box!
3. Explore the other 4 model notebooks

**The notebooks automatically find the framework** - no configuration needed!

### Path B: I Want to Use the Framework in My Own Code ğŸ’»

```python
# In your Python script or notebook
import sys
import os

# Add framework to path
sys.path.insert(0, '/path/to/Roy-QSAR-Generative-dev/src')

# Import what you need
from utils.qsar_utils_no_leakage import QSARDataProcessor
from qsar_validation.splitting_strategies import AdvancedSplitter
from qsar_validation.feature_scaling import FeatureScaler

# Use the modules
processor = QSARDataProcessor(smiles_col='SMILES')
# ... your code here
```

### Path C: I Want to Run the Tests ğŸ§ª

```bash
cd comprehensive_test
python test_all_modules_simple.py
```

This tests all 12 framework modules with synthetic QSAR data.

---

## ğŸ“š Step 4: Learn the Framework

### Quick Reference:

**Data Processing:**
```python
from utils.qsar_utils_no_leakage import QSARDataProcessor

processor = QSARDataProcessor(smiles_col='SMILES', target_col='Activity')
df = processor.canonicalize_smiles(df)
df = processor.remove_duplicates(df, strategy='average')
```

**Data Splitting:**
```python
from qsar_validation.splitting_strategies import AdvancedSplitter

splitter = AdvancedSplitter()
splits = splitter.scaffold_split(
    df,
    smiles_col='SMILES',
    target_col='Activity',
    test_size=0.2,
    val_size=0.1
)
train_idx, val_idx, test_idx = splits['train_idx'], splits['val_idx'], splits['test_idx']
```

**Feature Scaling:**
```python
from qsar_validation.feature_scaling import FeatureScaler

scaler = FeatureScaler(method='standard')
X_train_scaled = scaler.fit_transform(X_train)  # Fit on train only!
X_test_scaled = scaler.transform(X_test)        # Transform test
```

**Model Validation:**
```python
from qsar_validation.performance_validation import PerformanceValidator

validator = PerformanceValidator()
cv_results = validator.cross_validate(model, X_train, y_train, cv=5)
```

---

## ğŸ“ Step 5: Read the Documentation

1. **Framework overview:** [`README.md`](README.md) (main file)
2. **Notebook guide:** [`notebooks/README.md`](notebooks/README.md)
3. **Framework integration:** [`notebooks/FRAMEWORK_INTEGRATION_SUMMARY.md`](notebooks/FRAMEWORK_INTEGRATION_SUMMARY.md)
4. **Test results:** [`comprehensive_test/TEST_SUMMARY.md`](comprehensive_test/TEST_SUMMARY.md)
5. **Status report:** [`FINAL_STATUS_REPORT.md`](FINAL_STATUS_REPORT.md)

---

## âš¡ Common Issues

### Issue 1: "ModuleNotFoundError: No module named 'utils'"

**Cause:** Framework path not in Python path.

**Solution:**
```python
import sys
import os
sys.path.insert(0, '/absolute/path/to/Roy-QSAR-Generative-dev/src')
```

Or if running from notebooks folder:
```python
import sys
import os
current_dir = os.getcwd()
repo_root = os.path.abspath(os.path.join(current_dir, '..'))
sys.path.insert(0, os.path.join(repo_root, 'src'))
```

### Issue 2: "No module named 'rdkit'"

**Cause:** RDKit not installed.

**Solution:**
```bash
pip install rdkit
# or
conda install -c conda-forge rdkit
```

### Issue 3: Jupyter not starting

**Cause:** Jupyter not installed.

**Solution:**
```bash
pip install jupyter
```

### Issue 4: "No module named 'xgboost'" (or lightgbm)

**Cause:** Optional ML libraries not installed.

**Solution:**
```bash
pip install xgboost lightgbm
```

---

## ğŸ¯ What to Do Next

### If you're new to QSAR modeling:
1. âœ… Read `notebooks/DATA_LEAKAGE_FIX_EXAMPLE.ipynb`
2. âœ… Understand why data leakage matters
3. âœ… Try running one of the model notebooks
4. âœ… Adapt the workflow to your data

### If you're experienced with QSAR:
1. âœ… Review the module list in `README.md`
2. âœ… Pick the modules you need
3. âœ… Integrate into your existing workflow
4. âœ… Use the framework to validate your models

### If you want to contribute:
1. âœ… Run the test suite: `cd comprehensive_test && python test_all_modules_simple.py`
2. âœ… Understand the module structure in `src/`
3. âœ… Check open issues on GitHub
4. âœ… Submit a pull request!

---

## ğŸŒŸ Key Features to Know

### 1. Multi-Library Support
The framework works with:
- âœ… scikit-learn
- âœ… XGBoost
- âœ… LightGBM
- âœ… PyTorch
- âœ… TensorFlow/Keras
- âœ… Custom models

### 2. Modular Design
- Use only the modules you need
- No forced workflows
- Easy to integrate with existing code

### 3. Data Leakage Prevention
- Scaffold-based splitting
- Proper feature scaling (fit on train only)
- Near-duplicate detection (Tanimoto â‰¥ 0.95)
- Cross-validation with proper fold assignment

### 4. Comprehensive Validation
- Dataset quality analysis
- Model complexity control
- Activity cliff detection
- Uncertainty estimation
- Performance metrics

---

## ğŸ“§ Need Help?

1. **Check the documentation:**
   - Main README: [`README.md`](README.md)
   - Notebooks guide: [`notebooks/README.md`](notebooks/README.md)
   - Framework summary: [`notebooks/FRAMEWORK_INTEGRATION_SUMMARY.md`](notebooks/FRAMEWORK_INTEGRATION_SUMMARY.md)

2. **Run the examples:**
   - Notebooks: `notebooks/`
   - Test suite: `comprehensive_test/`

3. **Open an issue:**
   - GitHub Issues: https://github.com/bhatnira/Roy-QSAR-Generative-dev/issues

---

## âœ¨ Quick Tips

1. **Always remove duplicates BEFORE splitting**
   ```python
   df = processor.remove_duplicates(df, strategy='average')
   # THEN split
   ```

2. **Use scaffold-based splitting (not random!)**
   ```python
   splitter = AdvancedSplitter()
   splits = splitter.scaffold_split(...)  # âœ… Good
   # NOT: train_test_split(random_state=42)  # âŒ Bad
   ```

3. **Fit scalers on train only**
   ```python
   scaler.fit(X_train)           # âœ… Good
   X_train_scaled = scaler.transform(X_train)
   X_test_scaled = scaler.transform(X_test)
   
   # NOT: scaler.fit(X_all)  # âŒ Bad (data leakage!)
   ```

4. **Use proper cross-validation**
   ```python
   validator = PerformanceValidator()
   cv_results = validator.cross_validate(...)  # âœ… Good
   # NOT: random K-Fold  # âŒ Bad
   ```

---

## ğŸ‰ You're Ready!

You now have:
- âœ… Framework installed
- âœ… Dependencies ready
- âœ… Notebooks available
- âœ… Documentation accessible
- âœ… Quick reference at hand

**Start with:** `notebooks/DATA_LEAKAGE_FIX_EXAMPLE.ipynb`

**Questions?** Check the documentation or open an issue!

---

**Happy Modeling! ğŸš€**
