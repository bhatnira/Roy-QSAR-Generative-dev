"""
QSAR Data Leakage Prevention Utilities
=======================================

This module provides comprehensive tools to prevent data leakage in QSAR models:

1. Scaffold-based splitting (Bemis-Murcko)
2. Duplicate and near-duplicate detection/removal
3. Proper feature engineering workflow
4. Similarity analysis between train/test
5. Applicability domain estimation
6. Nested cross-validation support

Usage:
    from qsar_utils_no_leakage import QSARDataProcessor, ScaffoldSplitter
    
Author: Generated for low-data QSAR best practices
Date: January 2026
"""

import numpy as np
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors
from rdkit.Chem.Scaffolds import MurckoScaffold
from rdkit import DataStructs
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from typing import Tuple, List, Dict, Optional
import warnings

warnings.filterwarnings('ignore')


class QSARDataProcessor:
    """
    Comprehensive data processor for QSAR models that prevents data leakage.
    """
    
    def __init__(self, smiles_col='Canonical SMILES', target_col='IC50 uM'):
        """
        Initialize the QSAR data processor.
        
        Args:
            smiles_col: Name of the column containing SMILES strings
            target_col: Name of the column containing target values
        """
        self.smiles_col = smiles_col
        self.target_col = target_col
        self.train_scaler = None
        self.train_smiles = None
        self.train_fingerprints = None
        
    def canonicalize_smiles(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Canonicalize SMILES strings to ensure consistency.
        
        Args:
            df: DataFrame with SMILES column
            
        Returns:
            DataFrame with canonicalized SMILES
        """
        def canonicalize(smiles):
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol is not None:
                    return Chem.MolToSmiles(mol, canonical=True)
            except:
                return None
            return None
        
        df = df.copy()
        df[self.smiles_col] = df[self.smiles_col].apply(canonicalize)
        df = df.dropna(subset=[self.smiles_col])
        
        print(f"âœ“ Canonicalized {len(df)} SMILES")
        return df
    
    def remove_duplicates(self, df: pd.DataFrame, strategy='average') -> pd.DataFrame:
        """
        Remove duplicate molecules based on canonical SMILES.
        
        Args:
            df: DataFrame with SMILES and target columns
            strategy: How to handle replicates ('average', 'first', 'best')
            
        Returns:
            DataFrame without duplicates
        """
        df = df.copy()
        
        # Find duplicates
        duplicates = df[df.duplicated(subset=[self.smiles_col], keep=False)]
        n_duplicates = len(duplicates)
        
        if n_duplicates > 0:
            print(f"âš  Found {n_duplicates} duplicate molecules")
            
            if strategy == 'average':
                # Average the target values for duplicates
                df = df.groupby(self.smiles_col, as_index=False).agg({
                    col: 'mean' if col == self.target_col else 'first' 
                    for col in df.columns if col != self.smiles_col
                })
                print(f"âœ“ Averaged {n_duplicates} replicates")
            elif strategy == 'first':
                df = df.drop_duplicates(subset=[self.smiles_col], keep='first')
                print(f"âœ“ Kept first measurement for duplicates")
            else:
                # Keep the one with best (lowest) IC50
                df = df.sort_values(self.target_col).drop_duplicates(
                    subset=[self.smiles_col], keep='first'
                )
                print(f"âœ“ Kept best measurement for duplicates")
        
        print(f"âœ“ Final dataset: {len(df)} unique molecules")
        return df
    
    def remove_near_duplicates(self, df: pd.DataFrame, train_idx: np.ndarray, 
                               test_idx: np.ndarray, threshold=0.95) -> Tuple[np.ndarray, np.ndarray]:
        """
        Remove near-duplicate molecules between train and test sets.
        
        Args:
            df: DataFrame with SMILES
            train_idx: Training set indices
            test_idx: Test set indices
            threshold: Tanimoto similarity threshold
            
        Returns:
            Filtered train_idx, test_idx
        """
        train_smiles = df.iloc[train_idx][self.smiles_col].values
        test_smiles = df.iloc[test_idx][self.smiles_col].values
        
        # Generate fingerprints
        train_fps = [AllChem.GetMorganFingerprintAsBitVect(
            Chem.MolFromSmiles(smi), 2, 2048) for smi in train_smiles]
        test_fps = [AllChem.GetMorganFingerprintAsBitVect(
            Chem.MolFromSmiles(smi), 2, 2048) for smi in test_smiles]
        
        # Find near-duplicates
        to_remove = set()
        for i, test_fp in enumerate(test_fps):
            for train_fp in train_fps:
                similarity = DataStructs.TanimotoSimilarity(test_fp, train_fp)
                if similarity >= threshold:
                    to_remove.add(i)
                    break
        
        if to_remove:
            print(f"âš  Found {len(to_remove)} near-duplicates (Tanimoto â‰¥ {threshold})")
            test_idx = np.array([idx for i, idx in enumerate(test_idx) if i not in to_remove])
            print(f"âœ“ Removed from test set: {len(to_remove)} molecules")
        
        return train_idx, test_idx
    
    def analyze_similarity(self, df: pd.DataFrame, train_idx: np.ndarray, 
                          test_idx: np.ndarray) -> Dict:
        """
        Analyze similarity distribution between train and test sets.
        
        Args:
            df: DataFrame with SMILES
            train_idx: Training set indices
            test_idx: Test set indices
            
        Returns:
            Dictionary with similarity statistics
        """
        train_smiles = df.iloc[train_idx][self.smiles_col].values
        test_smiles = df.iloc[test_idx][self.smiles_col].values
        
        train_fps = [AllChem.GetMorganFingerprintAsBitVect(
            Chem.MolFromSmiles(smi), 2, 2048) for smi in train_smiles]
        test_fps = [AllChem.GetMorganFingerprintAsBitVect(
            Chem.MolFromSmiles(smi), 2, 2048) for smi in test_smiles]
        
        # Calculate max similarity for each test molecule
        max_similarities = []
        for test_fp in test_fps:
            sims = [DataStructs.TanimotoSimilarity(test_fp, train_fp) 
                   for train_fp in train_fps]
            max_similarities.append(max(sims))
        
        stats = {
            'mean': np.mean(max_similarities),
            'median': np.median(max_similarities),
            'min': np.min(max_similarities),
            'max': np.max(max_similarities),
            'similarities': max_similarities
        }
        
        print(f"\nğŸ“Š Train-Test Similarity Analysis:")
        print(f"   Mean max similarity: {stats['mean']:.3f}")
        print(f"   Median max similarity: {stats['median']:.3f}")
        print(f"   Range: [{stats['min']:.3f}, {stats['max']:.3f}]")
        
        return stats
    
    def fit_scaler(self, X_train: np.ndarray) -> StandardScaler:
        """
        Fit scaler on training data only (prevents leakage).
        
        Args:
            X_train: Training features
            
        Returns:
            Fitted StandardScaler
        """
        self.train_scaler = StandardScaler()
        self.train_scaler.fit(X_train)
        print("âœ“ Scaler fitted on training data only")
        return self.train_scaler
    
    def transform_features(self, X: np.ndarray, fit=False) -> np.ndarray:
        """
        Transform features using fitted scaler.
        
        Args:
            X: Features to transform
            fit: Whether to fit the scaler (only True for training data)
            
        Returns:
            Scaled features
        """
        if fit:
            return self.fit_scaler(X).transform(X)
        else:
            if self.train_scaler is None:
                raise ValueError("Scaler not fitted. Call fit_scaler() first.")
            return self.train_scaler.transform(X)
    
    def check_target_leakage(self, df: pd.DataFrame) -> None:
        """
        Check for potential target leakage in features.
        
        Args:
            df: DataFrame to check
        """
        print("\nğŸ” Checking for target leakage...")
        
        # Check for features with perfect correlation to target
        if self.target_col in df.columns:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            correlations = df[numeric_cols].corr()[self.target_col].abs()
            suspicious = correlations[correlations > 0.99].drop(self.target_col, errors='ignore')
            
            if len(suspicious) > 0:
                print(f"âš  WARNING: Found {len(suspicious)} features with suspiciously high correlation:")
                for feat, corr in suspicious.items():
                    print(f"   {feat}: {corr:.4f}")
            else:
                print("âœ“ No obvious target leakage detected")
    
    def estimate_applicability_domain(self, train_fps: List, test_fp, k=5) -> float:
        """
        Estimate if a test molecule is within the applicability domain.
        
        Args:
            train_fps: List of training fingerprints
            test_fp: Test fingerprint
            k: Number of nearest neighbors
            
        Returns:
            Average similarity to k nearest neighbors
        """
        similarities = [DataStructs.TanimotoSimilarity(test_fp, train_fp) 
                       for train_fp in train_fps]
        similarities.sort(reverse=True)
        return np.mean(similarities[:k])


class ScaffoldSplitter:
    """
    Scaffold-based splitting using Bemis-Murcko scaffolds.
    This prevents data leakage by ensuring entire scaffolds are in train OR test, not both.
    """
    
    def __init__(self, smiles_col='Canonical SMILES'):
        self.smiles_col = smiles_col
        
    def get_scaffold(self, smiles: str) -> str:
        """
        Get Bemis-Murcko scaffold from SMILES.
        
        Args:
            smiles: SMILES string
            
        Returns:
            Scaffold SMILES
        """
        try:
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                return ""
            scaffold = MurckoScaffold.GetScaffoldForMol(mol)
            return Chem.MolToSmiles(scaffold)
        except:
            return ""
    
    def scaffold_split(self, df: pd.DataFrame, test_size=0.2, val_size=0.1, 
                       random_state=42) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Split data based on molecular scaffolds.
        
        Args:
            df: DataFrame with SMILES column
            test_size: Fraction for test set
            val_size: Fraction for validation set
            random_state: Random seed
            
        Returns:
            train_idx, val_idx, test_idx
        """
        np.random.seed(random_state)
        
        # Get scaffolds for all molecules
        print("ğŸ”¬ Generating molecular scaffolds...")
        df = df.copy()
        df['scaffold'] = df[self.smiles_col].apply(self.get_scaffold)
        
        # Group by scaffold
        scaffold_groups = df.groupby('scaffold').groups
        print(f"âœ“ Found {len(scaffold_groups)} unique scaffolds")
        
        # Shuffle scaffolds
        scaffolds = list(scaffold_groups.keys())
        np.random.shuffle(scaffolds)
        
        # Assign scaffolds to splits
        n_total = len(df)
        n_test = int(n_total * test_size)
        n_val = int(n_total * val_size)
        
        train_idx, val_idx, test_idx = [], [], []
        
        for scaffold in scaffolds:
            indices = scaffold_groups[scaffold].tolist()
            
            if len(test_idx) < n_test:
                test_idx.extend(indices)
            elif len(val_idx) < n_val:
                val_idx.extend(indices)
            else:
                train_idx.extend(indices)
        
        train_idx = np.array(train_idx)
        val_idx = np.array(val_idx)
        test_idx = np.array(test_idx)
        
        print(f"\nğŸ“Š Scaffold-based split:")
        print(f"   Training: {len(train_idx)} molecules ({len(train_idx)/n_total*100:.1f}%)")
        print(f"   Validation: {len(val_idx)} molecules ({len(val_idx)/n_total*100:.1f}%)")
        print(f"   Test: {len(test_idx)} molecules ({len(test_idx)/n_total*100:.1f}%)")
        
        # Check for scaffold overlap (should be zero)
        train_scaffolds = set(df.iloc[train_idx]['scaffold'])
        val_scaffolds = set(df.iloc[val_idx]['scaffold'])
        test_scaffolds = set(df.iloc[test_idx]['scaffold'])
        
        overlap_train_test = train_scaffolds & test_scaffolds
        overlap_train_val = train_scaffolds & val_scaffolds
        overlap_val_test = val_scaffolds & test_scaffolds
        
        if overlap_train_test or overlap_train_val or overlap_val_test:
            print("âš  WARNING: Scaffold overlap detected!")
        else:
            print("âœ“ No scaffold overlap between splits (data leakage prevented)")
        
        return train_idx, val_idx, test_idx
    
    def scaffold_kfold(self, df: pd.DataFrame, n_splits=5, 
                       random_state=42) -> List[Tuple[np.ndarray, np.ndarray]]:
        """
        K-fold cross-validation with scaffold-based splitting.
        
        Args:
            df: DataFrame with SMILES column
            n_splits: Number of folds
            random_state: Random seed
            
        Returns:
            List of (train_idx, val_idx) tuples
        """
        np.random.seed(random_state)
        
        # Get scaffolds
        print("ğŸ”¬ Generating molecular scaffolds for K-fold CV...")
        df = df.copy()
        df['scaffold'] = df[self.smiles_col].apply(self.get_scaffold)
        
        # Group by scaffold
        scaffold_groups = df.groupby('scaffold').groups
        scaffolds = list(scaffold_groups.keys())
        np.random.shuffle(scaffolds)
        
        print(f"âœ“ Found {len(scaffold_groups)} unique scaffolds")
        print(f"âœ“ Creating {n_splits}-fold scaffold-based CV")
        
        # Distribute scaffolds to folds
        fold_indices = [[] for _ in range(n_splits)]
        fold_sizes = [0] * n_splits
        
        for scaffold in scaffolds:
            indices = scaffold_groups[scaffold].tolist()
            # Assign to the smallest fold
            min_fold = np.argmin(fold_sizes)
            fold_indices[min_fold].extend(indices)
            fold_sizes[min_fold] += len(indices)
        
        # Create train/val splits
        splits = []
        for i in range(n_splits):
            val_idx = np.array(fold_indices[i])
            train_idx = np.array([idx for j in range(n_splits) 
                                 if j != i for idx in fold_indices[j]])
            splits.append((train_idx, val_idx))
            
            print(f"   Fold {i+1}: Train={len(train_idx)}, Val={len(val_idx)}")
        
        return splits


def plot_similarity_distribution(similarity_stats: Dict, save_path=None):
    """
    Plot the similarity distribution between train and test sets.
    
    Args:
        similarity_stats: Dictionary from analyze_similarity()
        save_path: Optional path to save the plot
    """
    import matplotlib.pyplot as plt
    
    sims = similarity_stats['similarities']
    
    plt.figure(figsize=(10, 6))
    plt.hist(sims, bins=30, edgecolor='black', alpha=0.7)
    plt.axvline(similarity_stats['mean'], color='r', linestyle='--', 
                label=f'Mean: {similarity_stats["mean"]:.3f}')
    plt.axvline(similarity_stats['median'], color='g', linestyle='--', 
                label=f'Median: {similarity_stats["median"]:.3f}')
    plt.axvline(0.95, color='orange', linestyle=':', linewidth=2,
                label='High similarity threshold (0.95)')
    
    plt.xlabel('Maximum Tanimoto Similarity to Training Set', fontsize=12)
    plt.ylabel('Number of Test Molecules', fontsize=12)
    plt.title('Test Set Similarity to Training Set\n(Applicability Domain Check)', 
             fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(alpha=0.3)
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ Similarity plot saved to {save_path}")
    
    plt.show()


def print_leakage_prevention_summary():
    """
    Print a summary of data leakage prevention measures implemented.
    """
    summary = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘          DATA LEAKAGE PREVENTION - IMPLEMENTATION SUMMARY            â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    âœ… 1. Data Splitting Strategy
       â€¢ Scaffold-based splitting (Bemis-Murcko)
       â€¢ Entire scaffolds in train OR test (not both)
       â€¢ Alternative: Time-based or cluster-based splitting
    
    âœ… 2. Duplicate Handling
       â€¢ SMILES canonicalization
       â€¢ Exact duplicate removal with averaging
       â€¢ Near-duplicate detection (Tanimoto â‰¥ 0.95)
    
    âœ… 3. Feature Engineering Without Leakage
       â€¢ Scalers fitted on TRAINING data only
       â€¢ Transformations applied to validation/test separately
       â€¢ No feature selection on full dataset
    
    âœ… 4. Cross-Validation Strategy
       â€¢ Nested CV for hyperparameter tuning
       â€¢ Scaffold-based K-fold (not random)
       â€¢ Proper pipeline for each fold
    
    âœ… 5. Target Leakage Prevention
       â€¢ Target transformation before splitting
       â€¢ No target-derived features
       â€¢ Correlation analysis performed
    
    âœ… 6. Similarity Analysis
       â€¢ Train-test similarity distribution reported
       â€¢ Scaffold overlap checked (should be 0%)
       â€¢ Applicability domain estimated
    
    âœ… 7. Model Complexity Control
       â€¢ Regularization applied
       â€¢ Appropriate for dataset size
       â€¢ Cross-validation for evaluation
    
    ğŸ“Œ RECOMMENDATION: Always use scaffold-based splitting for QSAR models
    ğŸ“Œ CRITICAL: Fit preprocessing ONLY on training data
    ğŸ“Œ BEST PRACTICE: Report external validation results
    """
    print(summary)


# Example usage
if __name__ == "__main__":
    print_leakage_prevention_summary()
    
    # Example workflow
    """
    # Load data
    df = pd.read_excel('your_data.xlsx')
    
    # Initialize processor
    processor = QSARDataProcessor(smiles_col='Canonical SMILES', target_col='IC50 uM')
    
    # Clean data
    df = processor.canonicalize_smiles(df)
    df = processor.remove_duplicates(df, strategy='average')
    
    # Scaffold-based split
    splitter = ScaffoldSplitter(smiles_col='Canonical SMILES')
    train_idx, val_idx, test_idx = splitter.scaffold_split(df, test_size=0.2, val_size=0.1)
    
    # Remove near-duplicates
    train_idx, test_idx = processor.remove_near_duplicates(df, train_idx, test_idx, threshold=0.95)
    
    # Analyze similarity
    similarity_stats = processor.analyze_similarity(df, train_idx, test_idx)
    plot_similarity_distribution(similarity_stats)
    
    # Prepare features (example with fingerprints)
    # ... generate features ...
    
    # Scale features (fit on train only!)
    X_train_scaled = processor.transform_features(X_train, fit=True)
    X_val_scaled = processor.transform_features(X_val, fit=False)
    X_test_scaled = processor.transform_features(X_test, fit=False)
    
    # Train model...
    """
